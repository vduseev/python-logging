# fluentd/conf/fluent.conf
# https://www.jvt.me/posts/2021/09/29/fluentd-inner-json/

# FluentD own logs
<label @FLUENT_LOG>
  <match fluent.*>
    @type null
  </match>
</label>

# Logs coming from Docker containers
# tagged: docker
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker
</source>

# Transform logs from Docker
<filter docker>
  @type record_modifier
  <record>
    # "message" field is filled with contents from "log" field
    message ${record["log"]}
  </record>
  # Remove log field completely
  remove_keys log
</filter>

# Parse that embedded json log record
<filter docker>
  @type parser
  # Source field with JSON
  key_name message
  # Save original fields in the record
  reserve_data true
  # Remove message fild completely
  remove_key_name_field true
  # The parser configuration below will handle both JSON and non-JSON
  # values in the "message" field
  <parse>
    @type multi_format
    <pattern>
      format json
      time_key timestamp
      time_type string
      time_format %Y-%m-%dT%H:%M:%S.%N%z
    </pattern>
    <pattern>
      format none
    </pattern>
  </parse>
</filter>

# Process logs coming from Docker
<match docker>
  @type copy
  <store>
    @type opensearch
    host opensearch-index
    port 9200
    user admin
    password admin
    scheme https
    ssl_verify false
    # Use index name format like example-2022.02.02
    logstash_format true
    logstash_prefix example-logs
    # Flush records every second
    flush_interval 3s
    # OpenSearch complains if _type field is sent with the document
    suppress_type_name true
  </store>
  <store>
    @type stdout
  </store>
</match>

# Send rest of the logs to stdout
<match **.*>
  @type copy
  <store>
    @type stdout
  </store>
</match>
